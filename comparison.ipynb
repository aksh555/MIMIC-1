{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMISSION_DAYS</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>50801</th>\n",
       "      <th>50802</th>\n",
       "      <th>50803</th>\n",
       "      <th>50804</th>\n",
       "      <th>50805</th>\n",
       "      <th>...</th>\n",
       "      <th>G11</th>\n",
       "      <th>G12</th>\n",
       "      <th>G13</th>\n",
       "      <th>G14</th>\n",
       "      <th>G15</th>\n",
       "      <th>G16</th>\n",
       "      <th>G17</th>\n",
       "      <th>G18</th>\n",
       "      <th>G19</th>\n",
       "      <th>G20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>165315</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>152223</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>124321</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>462.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>161859</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>129635</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID  HADM_ID  ADMISSION_DAYS  GENDER  AGE  50801  50802  50803  \\\n",
       "0          22   165315               2       0   65  462.0    0.0   24.0   \n",
       "1          23   152223               6       1   71  462.0    0.0   24.0   \n",
       "2          23   124321               7       1   75  462.0    1.0   24.0   \n",
       "3          24   161859               3       1   39  462.0    0.0   24.0   \n",
       "4          25   129635               4       1   59  462.0    0.0   24.0   \n",
       "\n",
       "   50804  50805  ...  G11  G12  G13  G14  G15  G16  G17  G18  G19  G20  \n",
       "0   22.0    1.0  ...    0    0    0    0    0    0    0    1    1    0  \n",
       "1   26.0    1.0  ...    0    0    0    0    0    0    0    0    0    1  \n",
       "2   27.0    1.0  ...    0    0    0    0    0    1    0    0    0    1  \n",
       "3   27.0    1.0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "4   26.0    1.0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('dataset_with_hadm.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ADMISSION_DAYS',         'GENDER',            'AGE',            50801,\n",
      "                  50802,            50803,            50804,            50805,\n",
      "                  50806,            50808,\n",
      "       ...\n",
      "                  51512,            51513,            51514,            51515,\n",
      "                  51516,            51517,            51518,            51519,\n",
      "                  51529,            51532],\n",
      "      dtype='object', length=483) Index(['G1', 'G2', 'G3', 'G4', 'G5', 'G6', 'G7', 'G8', 'G9', 'G10', 'G11',\n",
      "       'G12', 'G13', 'G14', 'G15', 'G16', 'G17', 'G18', 'G19', 'G20'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_nohadm = df.drop(['HADM_ID','SUBJECT_ID'], axis=1)\n",
    "x = df_nohadm.iloc[:,:483]\n",
    "y = df_nohadm.iloc[:,483:]\n",
    "print(x.columns,y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=243 # is it gotta do with the prop of the split, shouldnt we regulate that using same seed..\n",
    "#what do u mean, like each time we are splitting x, y diff.. ya aren't we just storing the trained model\n",
    "# ya, i mean maybe what was in x_train while in training is now in x_test while predicting, so overfitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.15,random_state=seed)\n",
    "#x_train,x_val,y_train,y_val = train_test_split(x_tra,y_tra,test_size=0.95,random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score,roc_auc_score,confusion_matrix,hamming_loss\n",
    "from sklearn.externals import joblib\n",
    "rf = joblib.load(\"./Trained Models/Randomforest-C.pkl\")\n",
    "xgb = joblib.load(\"./Trained Models/XGBoostC.pkl\")\n",
    "cat = joblib.load(\"./Trained Models/CatBoostC.pkl\")\n",
    "lgbm = joblib.load(\"./Trained Models/LGBM-C.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6673877140694789 0.7449243897449993 0.9514177009908064 0.8434803816891454\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rf.predict(x_test)\n",
    "y_pred_xgb = xgb.predict(x_test)\n",
    "y_pred_cat = cat.predict(x_test)\n",
    "y_pred_lgbm = lgbm.predict(x_test)\n",
    "xgb_auc= roc_auc_score(y_test,y_pred_xgb)\n",
    "rf_auc= roc_auc_score(y_test,y_pred_rf)\n",
    "cat_auc= roc_auc_score(y_test,y_pred_cat)\n",
    "lgbm_auc= roc_auc_score(y_test,y_pred_lgbm)\n",
    "print(xgb_auc,lgbm_auc,rf_auc,cat_auc) # wait what! yep!!!\n",
    "#can u give me 5min sure\n",
    "# ya tell,wtf lol i mean what did u dowait ill show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16591499943483667 0.13311291963377417 0.02538148524923703 0.11575675370181983\n"
     ]
    }
   ],
   "source": [
    "xgb_ham = hamming_loss(y_test,y_pred_xgb)\n",
    "cat_ham = hamming_loss(y_test,y_pred_cat)\n",
    "lgbm_ham = hamming_loss(y_test,y_pred_lgbm)\n",
    "rf_ham = hamming_loss(y_test,y_pred_rf)\n",
    "print(xgb_ham,lgbm_ham,rf_ham,cat_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14744, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jaccard_score(y_test,y_pred,average='micro'))\n",
    "print(jaccard_score(y_test,y_pred,average='macro'))\n",
    "print(roc_auc_score(y_test,y_pred))\n",
    "print(hamming_loss(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold,KFold\n",
    "\n",
    "kf = KFold(train, shuffle=True, random_state=seed)\n",
    "\n",
    "\n",
    "## Creating Classes for stacking\n",
    "\n",
    "\n",
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):   #constructor\n",
    "        params['random_state'] = seed               #fixes random state\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        proba = self.clf.predict_proba(x)\n",
    "        return proba\n",
    "\n",
    "\n",
    "class XgbWrapper(object):\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 30)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        proba = self.gbdt.predict(xgb.DMatrix(x))\n",
    "        return proba\n",
    "\n",
    "\n",
    "def get_oof(clf):\n",
    "    oof_train = np.zeros((ntrain,n_classes))\n",
    "    oof_test = np.zeros((ntest,n_classes))\n",
    "    oof_test_skf = np.empty((ntest, NFOLDS*n_classes))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "        oof_train[test_index] = clf.predict_proba(x_te)\n",
    "        oof_test_skf[:,3*i: 3*i+3] = clf.predict_proba(x_test)\n",
    "        \n",
    "    for i in range(3):\n",
    "        oof_test[:,i] = (oof_test_skf[:,i]+oof_test_skf[:,i+3]+oof_test_skf[:,i+6]+oof_test_skf[:,i+9]+oof_test_skf[:,i+12])/5\n",
    "\n",
    "    \n",
    "    return oof_train, oof_test\n",
    "\n",
    "\n",
    "et_params = {\n",
    "    'n_jobs': 16,\n",
    "    'n_estimators': 10,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': 12,\n",
    "    #'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_jobs': 16,\n",
    "    'n_estimators': 10,\n",
    "    'max_features': 0.2,\n",
    "    'max_depth': 12,\n",
    "    #'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': 'multi:softprob',\n",
    "    'eta':0.1,\n",
    "    'max_depth':6,\n",
    "    'num_class':3,\n",
    "    'eval_metric':\"mlogloss\",\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "rd_params={\n",
    "    'alpha': 10\n",
    "}\n",
    "\n",
    "\n",
    "ls_params={\n",
    "    'alpha': 0.005\n",
    "}\n",
    "\n",
    "\n",
    "xg = XgbWrapper(seed=SEED, params=xgb_params)\n",
    "et = SklearnWrapper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "rf = SklearnWrapper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "\n",
    "xg_oof_train, xg_oof_test = get_oof(OneVsRestClassifier(xg))\n",
    "et_oof_train, et_oof_test = get_oof(OneVsRestClassifier(et))\n",
    "rf_oof_train, rf_oof_test = get_oof(OneVsRestClassifier(rf))\n",
    "\n",
    "\n",
    "print(\"XG-CV: {}\".format(log_loss(y_train, xg_oof_train)))\n",
    "print(\"ET-CV: {}\".format(log_loss(y_train, et_oof_train)))\n",
    "print(\"RF-CV: {}\".format(log_loss(y_train, rf_oof_train)))\n",
    "\n",
    "\n",
    "x_train = np.concatenate((xg_oof_train, et_oof_train, rf_oof_train), axis=1)\n",
    "x_test = np.concatenate((xg_oof_test, et_oof_test, rf_oof_test), axis=1)\n",
    "\n",
    "print(\"{},{}\".format(x_train.shape, x_test.shape))\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train) #DMatrix? its just like image-generator a form to take in data\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': 'multi:softprob',\n",
    "    'eta':0.1,\n",
    "    'max_depth':2,\n",
    "    'num_class':3,\n",
    "    'eval_metric':\"mlogloss\",\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7\n",
    "}\n",
    "\n",
    "res = xgb.cv(xgb_params, dtrain, num_boost_round=50, nfold=5, seed=SEED,\n",
    "             early_stopping_rounds=10, show_stdv=True)\n",
    "\n",
    "best_nrounds = res.shape[0] - 1\n",
    "cv_mean = res.iloc[-1, 0]\n",
    "cv_std = res.iloc[-1, 1]\n",
    "\n",
    "\n",
    "print('Ensemble-CV: {0}+{1}'.format(cv_mean, cv_std))\n",
    "gbdt = xgb.train(xgb_params, dtrain, best_nrounds)\n",
    "\n",
    "out_df = pd.DataFrame(gbdt.predict(dtest))\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"] # eh?\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_csv('xgstacker_starter.sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mimic)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
