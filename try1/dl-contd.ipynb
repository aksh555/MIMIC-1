{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import date,time,datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "lbl = LabelEncoder()\n",
    "mlb = MultiLabelBinarizer()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want different combination of train and test set execute ml first before this \n",
    "df = pd.read_pickle(\"./dataset.pkl\")\n",
    "x = df.iloc[:,:483].values\n",
    "y = df.iloc[:,483:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,CuDNNLSTM,CuDNNGRU,Flatten,Conv1D,Dropout,Activation,LeakyReLU,Input,MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44232, 483)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44232, 20)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train,(x_train.shape[0],1,x_train.shape[1]))\n",
    "y_train = np.reshape(y_train,(y_train.shape[0],1,y_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0:3032/337481,1:8924/337481,2:35608/337481,3:19366/337481,\n",
    "                 4:16271/337481,5:20008/337481,6:43243/337481,\n",
    "                 7:25281/337481,8:21200/337481,9:21782/337481,10:166/337481,\n",
    "                 11:8316/337481,12:10053/337481,13:3205/337481,\n",
    "                 14:5492/337481,15:19454/337481,16:1757/337481,17:23352/337481,18:16621/337481,19:34350/337481}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64,kernel_size=1,input_shape=(None,x_train.shape[2])))\n",
    "model.add(LeakyReLU(alpha=0.4))\n",
    "model.add(CuDNNLSTM(483,return_sequences=True))\n",
    "model.add(LeakyReLU(alpha=0.4))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=64,kernel_size=1))\n",
    "model.add(CuDNNGRU(483,return_sequences=True))\n",
    "model.add(LeakyReLU(alpha=0.4))\n",
    "model.add(Dense(161))\n",
    "model.add(Dense(81))\n",
    "model.add(Dense(y_train.shape[2],activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(metrics=['binary_accuracy','accuracy'],loss='binary_crossentropy',optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`class_weight` not supported for 3+ dimensional targets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a424f77f221f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mimic/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mimic/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 zip(y, sample_weights, class_weights,\n\u001b[0;32m--> 633\u001b[0;31m                     feed_sample_weight_modes)\n\u001b[0m\u001b[1;32m    634\u001b[0m             ]\n\u001b[1;32m    635\u001b[0m             \u001b[0;31m# Check that all arrays have the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mimic/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    629\u001b[0m             sample_weights = [\n\u001b[1;32m    630\u001b[0m                 \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m                 zip(y, sample_weights, class_weights,\n\u001b[1;32m    633\u001b[0m                     feed_sample_weight_modes)\n",
      "\u001b[0;32m~/anaconda3/envs/mimic/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_weights\u001b[0;34m(y, sample_weight, class_weight, sample_weight_mode)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             raise ValueError('`class_weight` not supported for '\n\u001b[0m\u001b[1;32m    495\u001b[0m                              '3+ dimensional targets.')\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `class_weight` not supported for 3+ dimensional targets."
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=10,batch_size=64,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, None, 64)          30976     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, None, 483)         1060668   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, None, 483)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, None, 483)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, None, 64)          30976     \n",
      "_________________________________________________________________\n",
      "cu_dnngru_3 (CuDNNGRU)       (None, None, 483)         795501    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, None, 483)         0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, None, 161)         77924     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, None, 81)          13122     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, None, 20)          1640      \n",
      "=================================================================\n",
      "Total params: 2,010,807\n",
      "Trainable params: 2,010,807\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.reshape(x_test,(x_test.shape[0],1,x_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.reshape(y_test,(y_test.shape[0],1,y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predtest = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predtrain = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44232, 1, 20)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_predtest,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.2852109332609875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score,roc_auc_score,confusion_matrix,hamming_loss\n",
    "#cm = confusion_matrix(y_test,y_pred) \n",
    "#Classification metrics can't handle a mix of multilabel-indicator and unknown targets\n",
    "print(jaccard_score(y_test,y_pred,average='micro'))\n",
    "print(jaccard_score(y_test,y_pred,average='macro'))\n",
    "print(roc_auc_score(y_test,y_pred))\n",
    "print(hamming_loss(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predtest_new = np.subtract(y_test,y_predtest)\n",
    "y_predtrain_new = np.subtract(y_train,y_predtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33174 samples, validate on 11058 samples\n",
      "Epoch 1/10\n",
      "33174/33174 [==============================] - 8s 248us/step - loss: -471.4342 - binary_accuracy: 1.5072e-06 - accuracy: 1.5072e-06 - val_loss: -2121.0246 - val_binary_accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "33174/33174 [==============================] - 7s 221us/step - loss: -9198.6341 - binary_accuracy: 1.5072e-06 - accuracy: 1.5072e-06 - val_loss: -18527.1197 - val_binary_accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "33174/33174 [==============================] - 7s 213us/step - loss: -40667.3166 - binary_accuracy: 1.5072e-06 - accuracy: 1.5072e-06 - val_loss: -62022.1860 - val_binary_accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "33174/33174 [==============================] - 7s 210us/step - loss: -104645.2607 - binary_accuracy: 1.5072e-06 - accuracy: 1.5072e-06 - val_loss: -137840.3222 - val_binary_accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "33174/33174 [==============================] - 7s 223us/step - loss: -207392.7052 - binary_accuracy: 1.5072e-06 - accuracy: 1.5072e-06 - val_loss: -248026.9424 - val_binary_accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "33174/33174 [==============================] - 7s 205us/step - loss: -348909.9449 - binary_accuracy: 1.5072e-06 - accuracy: 1.5072e-06 - val_loss: -397209.8896 - val_binary_accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "33174/33174 [==============================] - 7s 219us/step - loss: -532561.8329 - binary_accuracy: 1.5072e-06 - accuracy: 1.5072e-06 - val_loss: -586694.5704 - val_binary_accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "33174/33174 [==============================] - 7s 222us/step - loss: -762688.9114 - binary_accuracy: 1.5072e-06 - accuracy: 1.5072e-06 - val_loss: -818142.9387 - val_binary_accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "33174/33174 [==============================] - 7s 218us/step - loss: -1037560.3811 - binary_accuracy: 1.5072e-06 - accuracy: 1.5072e-06 - val_loss: -1088311.6509 - val_binary_accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "33174/33174 [==============================] - 7s 217us/step - loss: -1365154.2461 - binary_accuracy: 1.5072e-06 - accuracy: 1.5072e-06 - val_loss: -1418626.8374 - val_binary_accuracy: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f2e44096a50>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(metrics=['binary_accuracy','accuracy'],loss='binary_crossentropy',optimizer = 'adam')\n",
    "model.fit(x_train,y_predtrain_new,epochs=10,batch_size=64,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mimic)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
