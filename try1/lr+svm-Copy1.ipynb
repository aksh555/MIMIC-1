{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45526, 504)\n",
      "Requirement already up-to-date: gensim in /home/akshara/anaconda3/lib/python3.7/site-packages (3.8.1)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /home/akshara/anaconda3/lib/python3.7/site-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /home/akshara/anaconda3/lib/python3.7/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /home/akshara/anaconda3/lib/python3.7/site-packages (from gensim) (1.15.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /home/akshara/anaconda3/lib/python3.7/site-packages (from gensim) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: boto>=2.32 in /home/akshara/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /home/akshara/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in /home/akshara/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.10.42)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/akshara/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/akshara/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/akshara/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/akshara/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /home/akshara/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.14.0,>=1.13.42 in /home/akshara/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.13.42)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in /home/akshara/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.2.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /home/akshara/anaconda3/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.42->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /home/akshara/anaconda3/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.42->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already up-to-date: gensim in /home/akshara/anaconda3/lib/python3.7/site-packages (3.8.1)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /home/akshara/anaconda3/lib/python3.7/site-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /home/akshara/anaconda3/lib/python3.7/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /home/akshara/anaconda3/lib/python3.7/site-packages (from gensim) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /home/akshara/anaconda3/lib/python3.7/site-packages (from gensim) (1.15.1)\n",
      "Requirement already satisfied, skipping upgrade: boto>=2.32 in /home/akshara/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in /home/akshara/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.10.42)\n",
      "Requirement already satisfied, skipping upgrade: requests in /home/akshara/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /home/akshara/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.14.0,>=1.13.42 in /home/akshara/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.13.42)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in /home/akshara/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.2.1)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/akshara/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/akshara/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/akshara/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/akshara/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /home/akshara/anaconda3/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.42->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /home/akshara/anaconda3/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.42->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "combined_dataset = pd.read_pickle('../combined_dataset_notes.pkl')\n",
    "\n",
    "\n",
    "combined_dataset = combined_dataset.drop(['HADM_ID'], axis=1)\n",
    "print(combined_dataset.shape)\n",
    "#combined_dataset.head()\n",
    "\n",
    "only_text = combined_dataset[[\"text\",\"G1\",\"G2\",\"G3\",\"G4\",\"G5\",\"G6\",\"G7\",\"G8\",\"G9\",\"G10\",\"G11\",\"G12\",\"G13\",\"G14\",\"G15\",\"G16\",\"G17\",\"G18\",\"G19\",\"G20\"]]\n",
    "#print(only_text.shape)\n",
    "\n",
    "!pip install --upgrade gensim\n",
    "!pip install -U gensim\n",
    "\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "new_model = Word2Vec.load('model750-5-5.bin')\n",
    "#print(new_model)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold,KFold\n",
    "from sklearn.metrics import jaccard_score,roc_auc_score,confusion_matrix,hamming_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ADMISSION_DAYS</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>50801</th>\n",
       "      <th>50802</th>\n",
       "      <th>50803</th>\n",
       "      <th>50804</th>\n",
       "      <th>50805</th>\n",
       "      <th>50806</th>\n",
       "      <th>...</th>\n",
       "      <th>G11</th>\n",
       "      <th>G12</th>\n",
       "      <th>G13</th>\n",
       "      <th>G14</th>\n",
       "      <th>G15</th>\n",
       "      <th>G16</th>\n",
       "      <th>G17</th>\n",
       "      <th>G18</th>\n",
       "      <th>G19</th>\n",
       "      <th>G20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>47366</td>\n",
       "      <td>[chest, pa, lat, clip, clip, number, radiology...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47024</td>\n",
       "      <td>[pm, liver, gallbladder, u, single, organ, cli...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9046</td>\n",
       "      <td>[chest, portable, ap, clip, clip, number, radi...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>843</td>\n",
       "      <td>[pm, chest, pa, lat, clip, clip, number, radio...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>462.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43466</td>\n",
       "      <td>[pm, chest, portable, ap, different, physician...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 504 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  ADMISSION_DAYS  \\\n",
       "47366  [chest, pa, lat, clip, clip, number, radiology...               7   \n",
       "47024  [pm, liver, gallbladder, u, single, organ, cli...               5   \n",
       "9046   [chest, portable, ap, clip, clip, number, radi...              13   \n",
       "843    [pm, chest, pa, lat, clip, clip, number, radio...               5   \n",
       "43466  [pm, chest, portable, ap, different, physician...               5   \n",
       "\n",
       "       GENDER  AGE  50801  50802  50803  50804  50805  50806  ...  G11  G12  \\\n",
       "47366       0   35  462.0    0.0   24.0   26.0    1.0  104.0  ...    0    1   \n",
       "47024       1   60  462.0   -6.0   24.0   17.0    1.0  104.0  ...    0    1   \n",
       "9046        0   49  462.0    0.0   24.0   26.0    1.0  104.0  ...    0    0   \n",
       "843         1   61  462.0    2.0   24.0   28.0    1.0  103.0  ...    0    0   \n",
       "43466       0   54  462.0    0.0   23.0   25.0    1.0  106.0  ...    0    0   \n",
       "\n",
       "       G13  G14  G15  G16  G17  G18  G19  G20  \n",
       "47366    0    0    0    0    0    0    0    1  \n",
       "47024    0    0    0    1    0    0    0    0  \n",
       "9046     0    0    0    1    0    0    0    1  \n",
       "843      0    0    0    0    0    1    0    1  \n",
       "43466    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 504 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45526, 1) (45526, 20)\n"
     ]
    }
   ],
   "source": [
    "y = only_text.iloc[:,1:]\n",
    "x = only_text.iloc[:,:1]\n",
    "\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45526, 484) (45526, 20) Index([          'text', 'ADMISSION_DAYS',         'GENDER',            'AGE',\n",
      "                  50801,            50802,            50803,            50804,\n",
      "                  50805,            50806,\n",
      "       ...\n",
      "                  51512,            51513,            51514,            51515,\n",
      "                  51516,            51517,            51518,            51519,\n",
      "                  51529,            51532],\n",
      "      dtype='object', length=484) Index(['G1', 'G2', 'G3', 'G4', 'G5', 'G6', 'G7', 'G8', 'G9', 'G10', 'G11',\n",
      "       'G12', 'G13', 'G14', 'G15', 'G16', 'G17', 'G18', 'G19', 'G20'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "x_full = combined_dataset.iloc[:,:484]\n",
    "y_full = combined_dataset.iloc[:,484:]\n",
    "print(x_full.shape,y_full.shape,x_full.columns,y_full.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/pandas/core/generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "WordVectorz=dict(zip(new_model.wv.index2word,new_model.wv.vectors))\n",
    "class AverageEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim =100 # because we use 100 embedding points \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "AverageEmbeddingVectorizer(WordVectorz).fit(x,y)\n",
    "x.text = AverageEmbeddingVectorizer(WordVectorz).transform(x.text)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ADMISSION_DAYS</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>50801</th>\n",
       "      <th>50802</th>\n",
       "      <th>50803</th>\n",
       "      <th>50804</th>\n",
       "      <th>50805</th>\n",
       "      <th>50806</th>\n",
       "      <th>...</th>\n",
       "      <th>51512</th>\n",
       "      <th>51513</th>\n",
       "      <th>51514</th>\n",
       "      <th>51515</th>\n",
       "      <th>51516</th>\n",
       "      <th>51517</th>\n",
       "      <th>51518</th>\n",
       "      <th>51519</th>\n",
       "      <th>51529</th>\n",
       "      <th>51532</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>47366</td>\n",
       "      <td>0.421995</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47024</td>\n",
       "      <td>0.102772</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9046</td>\n",
       "      <td>0.241119</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>843</td>\n",
       "      <td>0.126102</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>462.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43466</td>\n",
       "      <td>0.348608</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24035</td>\n",
       "      <td>0.371063</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>653.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>108.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30073</td>\n",
       "      <td>0.451681</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>343.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25219</td>\n",
       "      <td>-0.169312</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>240.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33394</td>\n",
       "      <td>-0.105971</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>462.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38164</td>\n",
       "      <td>-0.127262</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>588.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45526 rows × 484 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           text  ADMISSION_DAYS  GENDER  AGE  50801  50802  50803  50804  \\\n",
       "47366  0.421995               7       0   35  462.0    0.0   24.0   26.0   \n",
       "47024  0.102772               5       1   60  462.0   -6.0   24.0   17.0   \n",
       "9046   0.241119              13       0   49  462.0    0.0   24.0   26.0   \n",
       "843    0.126102               5       1   61  462.0    2.0   24.0   28.0   \n",
       "43466  0.348608               5       0   54  462.0    0.0   23.0   25.0   \n",
       "...         ...             ...     ...  ...    ...    ...    ...    ...   \n",
       "24035  0.371063              25       1   60  653.0    1.0   26.0   28.0   \n",
       "30073  0.451681              10       0   58  343.0   -3.0   24.0   28.0   \n",
       "25219 -0.169312              17       1   23  240.0    4.0   24.0   29.0   \n",
       "33394 -0.105971               6       1   70  462.0    2.0   24.0   26.0   \n",
       "38164 -0.127262               6       1   89  588.0    1.0   24.0   25.0   \n",
       "\n",
       "       50805  50806  ...  51512  51513  51514  51515  51516  51517  51518  \\\n",
       "47366    1.0  104.0  ...    1.0  1.044    1.0    1.0    2.0    3.0    0.0   \n",
       "47024    1.0  104.0  ...    1.0  1.044    2.0    1.0    7.0    3.0    0.0   \n",
       "9046     1.0  104.0  ...    1.0  1.044    1.0    1.0    2.0    3.0    0.0   \n",
       "843      1.0  103.0  ...    1.0  1.044    1.0    1.0    1.0    3.0    0.0   \n",
       "43466    1.0  106.0  ...    1.0  1.044    1.0    1.0    2.0    3.0    0.0   \n",
       "...      ...    ...  ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "24035    1.3  108.0  ...    1.0  1.044    1.0    1.0    2.0    3.0    0.0   \n",
       "30073    1.0  104.0  ...    1.0  1.044    1.0    1.0    2.0    3.0    0.0   \n",
       "25219    1.0  104.0  ...    1.0  1.044    1.0    1.0    2.0    3.0    0.0   \n",
       "33394    1.0  105.0  ...    1.0  1.044    4.0    1.0    2.0    3.0    0.0   \n",
       "38164    1.0  104.0  ...    1.0  1.044    1.0    1.0    7.0    3.0    0.0   \n",
       "\n",
       "       51519  51529  51532  \n",
       "47366    0.0  135.5   43.0  \n",
       "47024    0.0  135.5   43.0  \n",
       "9046     0.0  135.5   43.0  \n",
       "843      0.0  135.5   43.0  \n",
       "43466    0.0  135.5   43.0  \n",
       "...      ...    ...    ...  \n",
       "24035    0.0  135.5   43.0  \n",
       "30073    0.0  135.5   43.0  \n",
       "25219    0.0  135.5   43.0  \n",
       "33394    0.0  135.5   43.0  \n",
       "38164    0.0  135.5   43.0  \n",
       "\n",
       "[45526 rows x 484 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_full['text'] = x.text\n",
    "x_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38697, 484) (38697, 20) (6829, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed=243 \n",
    "x_train_full,x_test_full,y_train_full,y_test_full = train_test_split(x_full,y_full,test_size=0.15,random_state = seed)\n",
    "print(x_train_full.shape,y_train_full.shape,y_test_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LGBMClassifier(boosting_type='gbdt',\n",
       "                                             class_weight=None,\n",
       "                                             colsample_bytree=1.0,\n",
       "                                             importance_type='split',\n",
       "                                             iterations=1000,\n",
       "                                             learning_rate=0.15, max_depth=-1,\n",
       "                                             min_child_samples=20,\n",
       "                                             min_child_weight=0.001,\n",
       "                                             min_split_gain=0.0,\n",
       "                                             n_estimators=100, n_jobs=-1,\n",
       "                                             num_leaves=31, objective=None,\n",
       "                                             random_state=None, reg_alpha=0.0,\n",
       "                                             reg_lambda=0.0, silent=True,\n",
       "                                             subsample=1.0,\n",
       "                                             subsample_for_bin=200000,\n",
       "                                             subsample_freq=0),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_full = OneVsRestClassifier(LGBMClassifier(iterations=1000,learning_rate=0.15,n_jobs=-1))\n",
    "lgb_full.fit(x_train_full,y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38697, 1) (38697, 20) (6829, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed=243 \n",
    "x_train_text,x_test_text,y_train_text,y_test_text = train_test_split(x,y,test_size=0.15,random_state = seed)\n",
    "print(x_train_text.shape,y_train_text.shape,y_test_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' for str \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm = MinMaxScaler(feature_range=(0, 1))\n",
    "x_train_mm = mm.fit_transform(x_train_full)\n",
    "x_test_mm = mm.transform(x_test_full)#needed here,i think u might need it for text also....'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "lgbm_text = joblib.load('w2v_lgbm.pkl')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''weights = {0:0.28,1:0.72}\n",
    "svc = OneVsRestClassifier(SVC(class_weight=weights))\n",
    "lr = OneVsRestClassifier(LogisticRegression(class_weight=weights))\n",
    "# u take over lol what u want me to do? train LR with some nice params'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "'''lr.fit(x_train_full,y_train_full)\n",
    "svc.fit(x_train_full,y_train_full)\n",
    "lr_str_pred = lr.predict(x_test_full)\n",
    "svc_str_pred = svc.predict(x_test_full)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting lgb proba on text and lr on str\n",
    "y_pred_prob = lgb_full.predict_proba(x_test_full)\n",
    "y_pred = lgb_full.predict(x_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5008530196897015\n",
      "0.38313090786641574\n",
      "0.665623807042951\n",
      "0.1820837604334456\n"
     ]
    }
   ],
   "source": [
    "print(jaccard_score(y_test_full,y_pred,average='micro'))\n",
    "print(jaccard_score(y_test_full,y_pred,average='macro'))\n",
    "print(roc_auc_score(y_test_full,y_pred))\n",
    "print(hamming_loss(y_test_full,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib  #0.66 0.18\n",
    "lgbm_text = joblib.load('w2v_lgbm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ac98f8e2cc8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlgb_pred_text_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgbm_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-dd17662ca97c>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     15\u001b[0m             np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n\u001b[1;32m     16\u001b[0m                     or [np.zeros(self.dim)], axis=0)\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         ])\n\u001b[1;32m     19\u001b[0m \u001b[0mAverageEmbeddingVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWordVectorz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-dd17662ca97c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m             np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n\u001b[1;32m     16\u001b[0m                     or [np.zeros(self.dim)], axis=0)\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         ])\n\u001b[1;32m     19\u001b[0m \u001b[0mAverageEmbeddingVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWordVectorz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "lgb_pred_text_prob = lgbm_text.predict_proba(x_test_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21738    0.031789\n",
       "47854   -0.296812\n",
       "3615    -0.086334\n",
       "37273    0.066688\n",
       "12132   -0.334977\n",
       "           ...   \n",
       "5542     0.136934\n",
       "57534    0.123680\n",
       "40358    0.221546\n",
       "24988    0.157372\n",
       "28595    0.519328\n",
       "Name: text, Length: 6829, dtype: float32"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_text.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def corr(a, b):\n",
    "    counts = 0\n",
    "  #first_df = pd.read_csv(first_file,index_col=0)\n",
    "  #second_df = pd.read_csv(second_file,index_col=0)\n",
    "  # assuming first column is `prediction_id` and second column is `prediction`\n",
    "    for i in range(a.shape[0]):  \n",
    "      #prediction = a[:,i] #first_df.columns[0]\n",
    "      # correlation\n",
    "        #print(\"Finding correlation row : {}\".format(i))\n",
    "      #print(\"Column to be measured: {}\".format(prediction))\n",
    "        cor = np.corrcoef(a[i,:],b[i,:])\n",
    "        #print(\"Pearson's correlation score: {}\".format(cor))\n",
    "        if(cor[0][1] < 0.7):\n",
    "            counts+=1\n",
    "      #print(\"Kendall's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='kendall')))\n",
    "      #print(\"Spearman's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='spearman')))\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-a339d47f260c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlgb_pred_text_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ml\u001b[0m\u001b[0;31m# this was high thats y its working better ig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#what was high? like correlation was low for many inspite o\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 4717 cat v cat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 4909 lgbm vs cat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-6e35d21d7c00>\u001b[0m in \u001b[0;36mcorr\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#print(\"Finding correlation row : {}\".format(i))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0;31m#print(\"Column to be measured: {}\".format(prediction))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mcor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m#print(\"Pearson's correlation score: {}\".format(cor))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "l = [corr(y_pred_prob,lgb_pred_text_prob)]\n",
    "l# this was high thats y its working better ig\n",
    "#what was high? like correlation was low for many inspite o\n",
    "# 4717 cat v cat\n",
    "# 4909 lgbm vs cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mimic)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
