{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "combined_dataset = pd.read_pickle('../combined_dataset_notes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45526, 504)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ADMISSION_DAYS</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>50801</th>\n",
       "      <th>50802</th>\n",
       "      <th>50803</th>\n",
       "      <th>50804</th>\n",
       "      <th>50805</th>\n",
       "      <th>50806</th>\n",
       "      <th>...</th>\n",
       "      <th>G11</th>\n",
       "      <th>G12</th>\n",
       "      <th>G13</th>\n",
       "      <th>G14</th>\n",
       "      <th>G15</th>\n",
       "      <th>G16</th>\n",
       "      <th>G17</th>\n",
       "      <th>G18</th>\n",
       "      <th>G19</th>\n",
       "      <th>G20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>47366</td>\n",
       "      <td>[chest, pa, lat, clip, clip, number, radiology...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47024</td>\n",
       "      <td>[pm, liver, gallbladder, u, single, organ, cli...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9046</td>\n",
       "      <td>[chest, portable, ap, clip, clip, number, radi...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>843</td>\n",
       "      <td>[pm, chest, pa, lat, clip, clip, number, radio...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>462.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43466</td>\n",
       "      <td>[pm, chest, portable, ap, different, physician...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 504 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  ADMISSION_DAYS  \\\n",
       "47366  [chest, pa, lat, clip, clip, number, radiology...               7   \n",
       "47024  [pm, liver, gallbladder, u, single, organ, cli...               5   \n",
       "9046   [chest, portable, ap, clip, clip, number, radi...              13   \n",
       "843    [pm, chest, pa, lat, clip, clip, number, radio...               5   \n",
       "43466  [pm, chest, portable, ap, different, physician...               5   \n",
       "\n",
       "       GENDER  AGE  50801  50802  50803  50804  50805  50806  ...  G11  G12  \\\n",
       "47366       0   35  462.0    0.0   24.0   26.0    1.0  104.0  ...    0    1   \n",
       "47024       1   60  462.0   -6.0   24.0   17.0    1.0  104.0  ...    0    1   \n",
       "9046        0   49  462.0    0.0   24.0   26.0    1.0  104.0  ...    0    0   \n",
       "843         1   61  462.0    2.0   24.0   28.0    1.0  103.0  ...    0    0   \n",
       "43466       0   54  462.0    0.0   23.0   25.0    1.0  106.0  ...    0    0   \n",
       "\n",
       "       G13  G14  G15  G16  G17  G18  G19  G20  \n",
       "47366    0    0    0    0    0    0    0    1  \n",
       "47024    0    0    0    1    0    0    0    0  \n",
       "9046     0    0    0    1    0    0    0    1  \n",
       "843      0    0    0    0    0    1    0    1  \n",
       "43466    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 504 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "combined_dataset = combined_dataset.drop(['HADM_ID'], axis=1)\n",
    "print(combined_dataset.shape)\n",
    "combined_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45526, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_text = combined_dataset[[\"text\",\"G1\",\"G2\",\"G3\",\"G4\",\"G5\",\"G6\",\"G7\",\"G8\",\"G9\",\"G10\",\"G11\",\"G12\",\"G13\",\"G14\",\"G15\",\"G16\",\"G17\",\"G18\",\"G19\",\"G20\"]]\n",
    "only_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: gensim in /home/akshara/anaconda3/lib/python3.7/site-packages (3.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /home/akshara/anaconda3/lib/python3.7/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /home/akshara/anaconda3/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /home/akshara/anaconda3/lib/python3.7/site-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /home/akshara/anaconda3/lib/python3.7/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: boto>=2.32 in /home/akshara/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /home/akshara/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in /home/akshara/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.10.42)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/akshara/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/akshara/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/akshara/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/akshara/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /home/akshara/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.14.0,>=1.13.42 in /home/akshara/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.13.42)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in /home/akshara/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.2.1)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /home/akshara/anaconda3/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.42->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /home/akshara/anaconda3/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.42->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n",
      "Requirement already up-to-date: gensim in /home/akshara/anaconda3/lib/python3.7/site-packages (3.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /home/akshara/anaconda3/lib/python3.7/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /home/akshara/anaconda3/lib/python3.7/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /home/akshara/anaconda3/lib/python3.7/site-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /home/akshara/anaconda3/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in /home/akshara/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.10.42)\n",
      "Requirement already satisfied, skipping upgrade: boto>=2.32 in /home/akshara/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /home/akshara/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in /home/akshara/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.2.1)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /home/akshara/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.14.0,>=1.13.42 in /home/akshara/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.13.42)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/akshara/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/akshara/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/akshara/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/akshara/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /home/akshara/anaconda3/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.42->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /home/akshara/anaconda3/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.42->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim\n",
    "!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=23960, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "#pass text here..\n",
    "#model = Word2Vec(combined_dataset.text,size=500, window=10, min_count=5, workers=56)#play around with param\n",
    "# summarize the loaded model\n",
    "#print(model)\n",
    "# summarize vocabulary\n",
    "#words = list(model.wv.vocab)\n",
    "#print(words)\n",
    "# access vector for one word\n",
    "#print(model['sentence'])\n",
    "# save model\n",
    "#model.save('model5000-10-5.bin')\n",
    "# load model\n",
    "model = Word2Vec.load('model300-10-5.bin')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = only_text.iloc[:,1:]\n",
    "x = only_text.iloc[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45526, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38697, 1) (6829, 1) (38697, 20) (6829, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed=243 \n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.15,random_state=seed)\n",
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.AverageEmbeddingVectorizer at 0x7f139fb872d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "WordVectorz=dict(zip(model.wv.index2word,model.wv.vectors))\n",
    "class AverageEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim =100 # because we use 100 embedding points \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "AverageEmbeddingVectorizer(WordVectorz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "from sklearn.metrics import jaccard_score,roc_auc_score,confusion_matrix,hamming_loss\n",
    "\n",
    "#clf_multilabel = OneVsRestClassifier(LGBMClassifier(iterations=1000,\n",
    "#                                                                     learning_rate=0.15))\n",
    "\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'OneVsRestClassifier(estimator=LGBMClassifier(boosting_type='gbdt',\n                                             class_weight=None,\n                                             colsample_bytree=1.0,\n                                             importance_type='split',\n                                             iterations=1000,\n                                             learning_rate=0.15, max_depth=-1,\n                                             min_child_samples=20,\n                                             min_child_weight=0.001,\n                                             min_split_gain=0.0,\n                                             n_estimators=100, n_jobs=-1,\n                                             num_leaves=31, objective=None,\n                                             random_state=None, reg_alpha=0.0,\n                                             reg_lambda=0.0, silent=True,\n                                             subsample=1.0,\n                                             subsample_for_bin=200000,\n                                             subsample_freq=0),\n                    n_jobs=None)' (type <class 'sklearn.multiclass.OneVsRestClassifier'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-059cc4d6b7e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m pipe1=Pipeline([(\"wordVectz\",AverageEmbeddingVectorizer(WordVectorz)),(\"multilabel\",OneVsRestClassifier(LGBMClassifier(iterations=1000,learning_rate=0.15,n_jobs=-1))),\n\u001b[0;32m----> 3\u001b[0;31m                (\"multilabel2\",OneVsRestClassifier(LGBMClassifier(iterations=1500,learning_rate=0.15,n_jobs=-1)))])\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpipe1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#run this and see but not here lets do this in a new nb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# clf_multilabel.fit(x_train.text,y_train)#have to now oopsitsk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps, memory, verbose)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m                                 \u001b[0;34m\"transformers and implement fit and transform \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                                 \u001b[0;34m\"or be the string 'passthrough' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                                 \"'%s' (type %s) doesn't\" % (t, type(t)))\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# We allow last estimator to be None as an identity transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'OneVsRestClassifier(estimator=LGBMClassifier(boosting_type='gbdt',\n                                             class_weight=None,\n                                             colsample_bytree=1.0,\n                                             importance_type='split',\n                                             iterations=1000,\n                                             learning_rate=0.15, max_depth=-1,\n                                             min_child_samples=20,\n                                             min_child_weight=0.001,\n                                             min_split_gain=0.0,\n                                             n_estimators=100, n_jobs=-1,\n                                             num_leaves=31, objective=None,\n                                             random_state=None, reg_alpha=0.0,\n                                             reg_lambda=0.0, silent=True,\n                                             subsample=1.0,\n                                             subsample_for_bin=200000,\n                                             subsample_freq=0),\n                    n_jobs=None)' (type <class 'sklearn.multiclass.OneVsRestClassifier'>) doesn't"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "pipe1=Pipeline([(\"wordVectz\",AverageEmbeddingVectorizer(WordVectorz)),\n",
    "                (\"multilabel\",OneVsRestClassifier(LGBMClassifier(iterations=1000,learning_rate=0.15,n_jobs=-1))),\n",
    "               (\"multilabel2\",OneVsRestClassifier(LGBMClassifier(iterations=1500,learning_rate=0.15,n_jobs=-1)))])\n",
    "pipe1.fit(x_train.text,y_train)#run this and see but not here lets do this in a new nb\n",
    "# clf_multilabel.fit(x_train.text,y_train)#have to now oopsitsk\n",
    "#ok?run again from top right? haan go on wait what both lgbm... yea there is a feeling i have just wanna try.. k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted1=pipe1.predict(x_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted1_prob_train = pipe1.predict_proba(x_train.text)\n",
    "predicted1_prob_test = pipe1.predict_proba(x_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5034983002608902\n",
      "0.39044713301507433\n",
      "0.6646507472338611\n",
      "0.1839288329184361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nCat w2v 500,10,5\\n0.6633380308436122\\n0.18253038512227265'"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(jaccard_score(y_test,predicted1,average='micro'))\n",
    "print(jaccard_score(y_test,predicted1,average='macro'))\n",
    "print(roc_auc_score(y_test,predicted1))\n",
    "print(hamming_loss(y_test,predicted1))\n",
    "'''\n",
    "Cat w2v 500,10,5\n",
    "0.6633380308436122\n",
    "0.18253038512227265'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6829, 19)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted1.shape #earlier with 1500d & mincount=3 - 0.6573500885474709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe1.fit(x_train.text,y_train)\n",
    "predicted1_prob_testdf = pd.DataFrame(predicted1_prob_test)\n",
    "predicted1_prob_traindf = pd.DataFrame(predicted1_prob_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6829, 20)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted1_prob_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.006364</td>\n",
       "      <td>0.014811</td>\n",
       "      <td>0.381461</td>\n",
       "      <td>0.244952</td>\n",
       "      <td>0.226117</td>\n",
       "      <td>0.133170</td>\n",
       "      <td>0.422299</td>\n",
       "      <td>0.114607</td>\n",
       "      <td>0.154242</td>\n",
       "      <td>0.135912</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.029295</td>\n",
       "      <td>0.206063</td>\n",
       "      <td>0.008920</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.144964</td>\n",
       "      <td>0.027488</td>\n",
       "      <td>0.984861</td>\n",
       "      <td>0.983045</td>\n",
       "      <td>0.347243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.060448</td>\n",
       "      <td>0.020596</td>\n",
       "      <td>0.792334</td>\n",
       "      <td>0.469381</td>\n",
       "      <td>0.554800</td>\n",
       "      <td>0.337727</td>\n",
       "      <td>0.471109</td>\n",
       "      <td>0.146749</td>\n",
       "      <td>0.755750</td>\n",
       "      <td>0.457869</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.103819</td>\n",
       "      <td>0.162318</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.527361</td>\n",
       "      <td>0.014730</td>\n",
       "      <td>0.352813</td>\n",
       "      <td>0.349358</td>\n",
       "      <td>0.289949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.047712</td>\n",
       "      <td>0.474600</td>\n",
       "      <td>0.111793</td>\n",
       "      <td>0.401464</td>\n",
       "      <td>0.651509</td>\n",
       "      <td>0.855404</td>\n",
       "      <td>0.151393</td>\n",
       "      <td>0.127526</td>\n",
       "      <td>0.281706</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.029521</td>\n",
       "      <td>0.174612</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.310654</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>0.515857</td>\n",
       "      <td>0.806501</td>\n",
       "      <td>0.454475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.009529</td>\n",
       "      <td>0.030799</td>\n",
       "      <td>0.778939</td>\n",
       "      <td>0.136471</td>\n",
       "      <td>0.182365</td>\n",
       "      <td>0.104084</td>\n",
       "      <td>0.989231</td>\n",
       "      <td>0.141261</td>\n",
       "      <td>0.191664</td>\n",
       "      <td>0.090097</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.020778</td>\n",
       "      <td>0.120590</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.082227</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.168287</td>\n",
       "      <td>0.069491</td>\n",
       "      <td>0.452310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.155675</td>\n",
       "      <td>0.350358</td>\n",
       "      <td>0.850952</td>\n",
       "      <td>0.722703</td>\n",
       "      <td>0.364650</td>\n",
       "      <td>0.714532</td>\n",
       "      <td>0.905861</td>\n",
       "      <td>0.852393</td>\n",
       "      <td>0.701567</td>\n",
       "      <td>0.771462</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.397246</td>\n",
       "      <td>0.220130</td>\n",
       "      <td>0.035454</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.672055</td>\n",
       "      <td>0.041518</td>\n",
       "      <td>0.754205</td>\n",
       "      <td>0.359311</td>\n",
       "      <td>0.675329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6824</td>\n",
       "      <td>0.095784</td>\n",
       "      <td>0.137530</td>\n",
       "      <td>0.860846</td>\n",
       "      <td>0.712012</td>\n",
       "      <td>0.310655</td>\n",
       "      <td>0.738019</td>\n",
       "      <td>0.927311</td>\n",
       "      <td>0.315240</td>\n",
       "      <td>0.471653</td>\n",
       "      <td>0.871125</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.494851</td>\n",
       "      <td>0.312031</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.528199</td>\n",
       "      <td>0.029597</td>\n",
       "      <td>0.859444</td>\n",
       "      <td>0.631167</td>\n",
       "      <td>0.771659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6825</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.068985</td>\n",
       "      <td>0.846435</td>\n",
       "      <td>0.632877</td>\n",
       "      <td>0.799036</td>\n",
       "      <td>0.569135</td>\n",
       "      <td>0.780485</td>\n",
       "      <td>0.465946</td>\n",
       "      <td>0.804712</td>\n",
       "      <td>0.705267</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.456766</td>\n",
       "      <td>0.196635</td>\n",
       "      <td>0.019320</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.601936</td>\n",
       "      <td>0.041650</td>\n",
       "      <td>0.657041</td>\n",
       "      <td>0.343640</td>\n",
       "      <td>0.647979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6826</td>\n",
       "      <td>0.042937</td>\n",
       "      <td>0.040011</td>\n",
       "      <td>0.640910</td>\n",
       "      <td>0.506048</td>\n",
       "      <td>0.862476</td>\n",
       "      <td>0.538513</td>\n",
       "      <td>0.452046</td>\n",
       "      <td>0.583061</td>\n",
       "      <td>0.328257</td>\n",
       "      <td>0.358777</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.209272</td>\n",
       "      <td>0.294012</td>\n",
       "      <td>0.011878</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.636439</td>\n",
       "      <td>0.031056</td>\n",
       "      <td>0.493248</td>\n",
       "      <td>0.481291</td>\n",
       "      <td>0.412246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6827</td>\n",
       "      <td>0.105662</td>\n",
       "      <td>0.080924</td>\n",
       "      <td>0.846555</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>0.317569</td>\n",
       "      <td>0.542417</td>\n",
       "      <td>0.959383</td>\n",
       "      <td>0.258478</td>\n",
       "      <td>0.417617</td>\n",
       "      <td>0.915276</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.367771</td>\n",
       "      <td>0.196251</td>\n",
       "      <td>0.009987</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.452880</td>\n",
       "      <td>0.026391</td>\n",
       "      <td>0.855679</td>\n",
       "      <td>0.562148</td>\n",
       "      <td>0.643258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6828</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>0.065920</td>\n",
       "      <td>0.731566</td>\n",
       "      <td>0.123670</td>\n",
       "      <td>0.108444</td>\n",
       "      <td>0.115051</td>\n",
       "      <td>0.989617</td>\n",
       "      <td>0.237605</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.136465</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.049520</td>\n",
       "      <td>0.122557</td>\n",
       "      <td>0.061927</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.071558</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.372009</td>\n",
       "      <td>0.153516</td>\n",
       "      <td>0.321672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6829 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.006364  0.014811  0.381461  0.244952  0.226117  0.133170  0.422299   \n",
       "1     0.060448  0.020596  0.792334  0.469381  0.554800  0.337727  0.471109   \n",
       "2     0.011747  0.047712  0.474600  0.111793  0.401464  0.651509  0.855404   \n",
       "3     0.009529  0.030799  0.778939  0.136471  0.182365  0.104084  0.989231   \n",
       "4     0.155675  0.350358  0.850952  0.722703  0.364650  0.714532  0.905861   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6824  0.095784  0.137530  0.860846  0.712012  0.310655  0.738019  0.927311   \n",
       "6825  0.070175  0.068985  0.846435  0.632877  0.799036  0.569135  0.780485   \n",
       "6826  0.042937  0.040011  0.640910  0.506048  0.862476  0.538513  0.452046   \n",
       "6827  0.105662  0.080924  0.846555  0.791480  0.317569  0.542417  0.959383   \n",
       "6828  0.013077  0.065920  0.731566  0.123670  0.108444  0.115051  0.989617   \n",
       "\n",
       "             7         8         9        10        11        12        13  \\\n",
       "0     0.114607  0.154242  0.135912  0.000083  0.029295  0.206063  0.008920   \n",
       "1     0.146749  0.755750  0.457869  0.001473  0.103819  0.162318  0.017451   \n",
       "2     0.151393  0.127526  0.281706  0.000056  0.029521  0.174612  0.006954   \n",
       "3     0.141261  0.191664  0.090097  0.000048  0.020778  0.120590  0.015656   \n",
       "4     0.852393  0.701567  0.771462  0.001481  0.397246  0.220130  0.035454   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6824  0.315240  0.471653  0.871125  0.000228  0.494851  0.312031  0.008207   \n",
       "6825  0.465946  0.804712  0.705267  0.001412  0.456766  0.196635  0.019320   \n",
       "6826  0.583061  0.328257  0.358777  0.000726  0.209272  0.294012  0.011878   \n",
       "6827  0.258478  0.417617  0.915276  0.000217  0.367771  0.196251  0.009987   \n",
       "6828  0.237605  0.191000  0.136465  0.000037  0.049520  0.122557  0.061927   \n",
       "\n",
       "            14        15        16        17        18        19  \n",
       "0     0.000142  0.144964  0.027488  0.984861  0.983045  0.347243  \n",
       "1     0.000144  0.527361  0.014730  0.352813  0.349358  0.289949  \n",
       "2     0.000131  0.310654  0.001712  0.515857  0.806501  0.454475  \n",
       "3     0.000347  0.082227  0.001190  0.168287  0.069491  0.452310  \n",
       "4     0.000101  0.672055  0.041518  0.754205  0.359311  0.675329  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "6824  0.000102  0.528199  0.029597  0.859444  0.631167  0.771659  \n",
       "6825  0.000352  0.601936  0.041650  0.657041  0.343640  0.647979  \n",
       "6826  0.000791  0.636439  0.031056  0.493248  0.481291  0.412246  \n",
       "6827  0.000130  0.452880  0.026391  0.855679  0.562148  0.643258  \n",
       "6828  0.000110  0.071558  0.001343  0.372009  0.153516  0.321672  \n",
       "\n",
       "[6829 rows x 20 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted1_prob_testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train.text.to_pickle('./train-nlp.pkl')\n",
    "x_test.text.to_pickle('./test-nlp.pkl')\n",
    "y_train.to_pickle('./y_train-nlp.pkl')\n",
    "y_test.to_pickle('./y_test-nlp.pkl')\n",
    "predicted1_prob_testdf.to_pickle('./pred-test-xgb.pkl')\n",
    "predicted1_prob_traindf.to_pickle('./pred-train-xgb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w2v_lgbm.pkl']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(pipe1, \"w2v_lgbm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "textlgbm =  joblib.load(\"w2v_lgbm.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-034cadf9aebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvalc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cat1-C.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtextc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./w2v.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlgbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./LGBM1-C.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mimic/lib/python3.7/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mimic/lib/python3.7/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
      "\u001b[0;32m~/anaconda3/envs/mimic/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mimic/lib/python3.7/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mNDArrayWrapper\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0mcompatibility\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mUnpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;31m# For backward compatibility, we support NDArrayWrapper objects.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mimic/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36mload_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1558\u001b[0m             \u001b[0minst_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m             \u001b[0mintern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1560\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1561\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m                     \u001b[0minst_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mintern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "valc = joblib.load(\"cat1-C.pkl\")\n",
    "textc = joblib.load(\"./w2v.pkl\")\n",
    "lgbm = joblib.load(\"./LGBM1-C.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_full = combined_dataset.iloc[:,:484]\n",
    "y_full = combined_dataset.iloc[:,484:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([          'text', 'ADMISSION_DAYS',         'GENDER',            'AGE',\n",
       "                  50801,            50802,            50803,            50804,\n",
       "                  50805,            50806,\n",
       "       ...\n",
       "                  51512,            51513,            51514,            51515,\n",
       "                  51516,            51517,            51518,            51519,\n",
       "                  51529,            51532],\n",
       "      dtype='object', length=484)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADMISSION_DAYS</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>50801</th>\n",
       "      <th>50802</th>\n",
       "      <th>50803</th>\n",
       "      <th>50804</th>\n",
       "      <th>50805</th>\n",
       "      <th>50806</th>\n",
       "      <th>50808</th>\n",
       "      <th>...</th>\n",
       "      <th>51512</th>\n",
       "      <th>51513</th>\n",
       "      <th>51514</th>\n",
       "      <th>51515</th>\n",
       "      <th>51516</th>\n",
       "      <th>51517</th>\n",
       "      <th>51518</th>\n",
       "      <th>51519</th>\n",
       "      <th>51529</th>\n",
       "      <th>51532</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>21738</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>462.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47854</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3615</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>462.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37273</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12132</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>338.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5542</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>584.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57534</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40358</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24988</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>391.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28595</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6829 rows × 483 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ADMISSION_DAYS  GENDER  AGE  50801  50802  50803  50804  50805  50806  \\\n",
       "21738              10       1   83  462.0    5.0   24.0   32.0    1.0  104.0   \n",
       "47854               3       1   66  462.0   -2.0   22.0   22.0    1.0  105.0   \n",
       "3615                8       1   80  462.0    1.0   24.0   26.0    1.0  104.0   \n",
       "37273               5       1   46  462.0    0.0   24.0   26.0    1.0  104.0   \n",
       "12132              27       1   85  338.0   -1.0   24.0   25.0    1.0  100.0   \n",
       "...               ...     ...  ...    ...    ...    ...    ...    ...    ...   \n",
       "5542               16       1   82  584.0    0.0   24.0   26.0    1.0  104.0   \n",
       "57534              13       1   56  462.0    0.0   24.0   29.0    1.0  102.0   \n",
       "40358              12       1   36  462.0    0.0   24.0   26.0    1.0  104.0   \n",
       "24988              14       1   50  391.0    6.0   24.0   32.0    1.0  101.0   \n",
       "28595              17       0    0  462.0   -5.0   24.0   23.0    1.0  104.0   \n",
       "\n",
       "       50808  ...  51512  51513  51514  51515  51516  51517  51518  51519  \\\n",
       "21738   1.12  ...    1.0  1.044    1.0    1.0    2.0    3.0    0.0    0.0   \n",
       "47854   1.10  ...    1.0  1.044    1.0    1.0    2.0    3.0    0.0    0.0   \n",
       "3615    1.15  ...    1.0  1.044    1.0    1.0    2.0    3.0    0.0    0.0   \n",
       "37273   1.12  ...    1.0  1.044    4.0    1.0    2.0    3.0    0.0    0.0   \n",
       "12132   1.14  ...    1.0  1.044    0.2    1.0    0.0    3.0    0.0    0.0   \n",
       "...      ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "5542    1.12  ...    1.0  1.044    0.2    1.0    7.0    3.0    0.0    0.0   \n",
       "57534   1.25  ...    1.0  1.044    1.0    1.0    2.0    3.0    0.0    0.0   \n",
       "40358   1.12  ...    1.0  1.044    1.0    1.0    2.0    3.0    0.0    0.0   \n",
       "24988   1.18  ...    1.0  1.044    0.2    1.0    0.0    3.0    0.0    0.0   \n",
       "28595   1.12  ...    1.0  1.044    1.0    1.0    2.0    3.0    0.0    0.0   \n",
       "\n",
       "       51529  51532  \n",
       "21738  135.5   43.0  \n",
       "47854  135.5   43.0  \n",
       "3615   135.5   43.0  \n",
       "37273  135.5   43.0  \n",
       "12132  135.5   43.0  \n",
       "...      ...    ...  \n",
       "5542   135.5   43.0  \n",
       "57534  135.5   43.0  \n",
       "40358  135.5   43.0  \n",
       "24988  135.5   43.0  \n",
       "28595  135.5   43.0  \n",
       "\n",
       "[6829 rows x 483 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed=243 \n",
    "x_train_full,x_test_full,y_train_full,y_test_full = train_test_split(x_full,y_full,test_size=0.15,random_state=seed)\n",
    "x_test_full.iloc[:,1:484]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38697, 20) (38697, 20)\n"
     ]
    }
   ],
   "source": [
    "y_pred_catnum = valc.predict(x_train_full.iloc[:,1:484])\n",
    "y_pred_catext = textc.predict(x_train_full.text)\n",
    "\n",
    "print(y_pred_catnum.shape,y_pred_catext.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38697, 20)\n"
     ]
    }
   ],
   "source": [
    "y_pred_lg = lgbm.predict(x_train_full.iloc[:,1:484])\n",
    "y_pred_lg_prob = lgbm.predict_proba(x_train_full.iloc[:,1:484])\n",
    "print(y_pred_lg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-278-2b220e1dd413>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred_lgbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextlgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m484\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred_lgbm_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextlgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m484\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_lgbm_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mimic/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-99-87b9b264e6d7>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     14\u001b[0m             np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n\u001b[1;32m     15\u001b[0m                     or [np.zeros(self.dim)], axis=0)\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         ])\n\u001b[1;32m     18\u001b[0m \u001b[0mAverageEmbeddingVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWordVectorz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-99-87b9b264e6d7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m             np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n\u001b[1;32m     15\u001b[0m                     or [np.zeros(self.dim)], axis=0)\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         ])\n\u001b[1;32m     18\u001b[0m \u001b[0mAverageEmbeddingVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWordVectorz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "y_pred_lgbm = textlgbm.predict(x_test_full.text)#need str stuff ? this is text only, we were using lgbm for str and cat for text\n",
    "y_pred_lgbm_prob = textlgbm.predict_proba(x_test_full.text)\n",
    "\n",
    "print(y_pred_lgbm_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6829, 20)\n"
     ]
    }
   ],
   "source": [
    "y_pred_lgbm_text = textlgbm.predict(x_test_full.text)\n",
    "y_pred_lgbm_text_prob = textlgbm.predict_proba(x_test_full.text)\n",
    "\n",
    "print(y_pred_lgbm_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6829, 20) (6829, 20)\n"
     ]
    }
   ],
   "source": [
    "y_pred_catnum_prob = valc.predict_proba(x_test_full.iloc[:,1:484])\n",
    "y_pred_catext_prob = textc.predict_proba(x_test_full.text)\n",
    "print(y_pred_catnum.shape,y_pred_catext.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what all is needed lol \n",
    "# i need lgbm for str and cat for text on train or test or both? both na?\n",
    "y_pred_lg_prob_train = lgbm.predict_proba(x_train_full.iloc[:,1:484])\n",
    "y_pred_lg_prob_test = lgbm.predict_proba(x_test_full.iloc[:,1:484])\n",
    "y_pred_catext_prob_train = textc.predict_proba(x_train_full.text)\n",
    "y_pred_catext_prob_test = textc.predict_proba(x_test_full.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_comb =y_pred_lg_prob_test+np.subtract(1,y_pred_catext_prob)\n",
    "#y_comb/=2\n",
    "y_comb = y_comb.round()\n",
    "y_comb = np.where(y_comb>1,1,0)#wait u got this wrong\n",
    "#just try this, according to me text can give more info, and i would change w2v to 1000 \n",
    "# 0.7052650131769738\n",
    "# 0.1599868209108215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07168119091098218\n",
      "0.13843890622090185\n",
      "0.561602477838084\n",
      "0.29404012300483234\n"
     ]
    }
   ],
   "source": [
    "# predicting on avg of both probs on test set\n",
    "print(jaccard_score(y_test,y_comb,average='micro'))\n",
    "print(jaccard_score(y_test,y_comb,average='macro'))\n",
    "print(roc_auc_score(y_test,y_comb))\n",
    "print(hamming_loss(y_test,y_comb))\n",
    "#0.6646507472338611"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6937055799183427\n",
      "0.648084064314032\n",
      "0.8135841276855682\n",
      "0.10468640979920923\n"
     ]
    }
   ],
   "source": [
    "# predicting on train set\n",
    "print(jaccard_score(y_train_full,y_comb,average='micro'))\n",
    "print(jaccard_score(y_train_full,y_comb,average='macro'))\n",
    "print(roc_auc_score(y_train_full,y_comb))\n",
    "print(hamming_loss(y_train_full,y_comb))\n",
    "#0.6646507472338611"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_sum = 0.7664439688584423/0.17394371656717575 + 0.8135841276855682/0.10468640979920923\n",
    "#auc/ham worked...\n",
    "y_comb = (y_pred_lg_prob_test*0.7664439688584423/0.17394371656717575 +y_pred_catext_prob_test*0.8135841276855682/0.10468640979920923)/auc_sum\n",
    "y_comb = y_comb.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def corr(a, b):\n",
    "    counts = 0\n",
    "  #first_df = pd.read_csv(first_file,index_col=0)\n",
    "  #second_df = pd.read_csv(second_file,index_col=0)\n",
    "  # assuming first column is `prediction_id` and second column is `prediction`\n",
    "    for i in range(a.shape[0]):  \n",
    "      #prediction = a[:,i] #first_df.columns[0]\n",
    "      # correlation\n",
    "        #print(\"Finding correlation row : {}\".format(i))\n",
    "      #print(\"Column to be measured: {}\".format(prediction))\n",
    "        cor = np.corrcoef(a[i,:],b[i,:])\n",
    "        #print(\"Pearson's correlation score: {}\".format(cor))\n",
    "        if(cor[0][1] < 0.7):\n",
    "            counts+=1\n",
    "      #print(\"Kendall's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='kendall')))\n",
    "      #print(\"Spearman's correlation score: {}\".format(first_df[prediction].corr(second_df[prediction],method='spearman')))\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[521]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [corr(y_pred_catnum,y_pred_lg)]\n",
    "l# this was high thats y its working better ig\n",
    "#what was high? like correlation was low for many inspite o\n",
    "# 4717 cat v cat\n",
    "# 4909 lgbm vs cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[ ('text', textc), ('val', valc)]\n",
    "ensemble = OneVsRestClassifier(VotingClassifier(estimators, voting='soft'))\n",
    "ensemble.fit(x_train_mm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mimic)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
